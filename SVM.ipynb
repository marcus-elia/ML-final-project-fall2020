{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn utilities\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "image_path = \"Car1Rotations/car1_{}_{}.png\".format(image_resolution, 0)\n",
    "digits = datasets.load_digits()\n",
    "data = []\n",
    "data2 = []\n",
    "for i in range(360):\n",
    "    image_path1 = \"Car1Rotations/car1_{}_{}.png\".format(image_resolution, i)\n",
    "    image_path2 = \"Car2Rotations/car2_{}_{}.png\".format(image_resolution, i)\n",
    "    img1 = plt.imread(image_path1)\n",
    "    img2 = plt.imread(image_path2)\n",
    "    rgb_weights = [0.2989, 0.5870, 0.1140]\n",
    "    grayscale_img1 = np.dot(img1, rgb_weights)\n",
    "    grayscale_img2 = np.dot(img2, rgb_weights)\n",
    "    img_flat1 = grayscale_img1.flatten()\n",
    "    img_flat2 = grayscale_img2.flatten()\n",
    "    data.append(img_flat1)\n",
    "    data2.append(img_flat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset1: (360, 147456)\n",
      "and shape of dataset2:(360, 147456)\n",
      " and target: (360,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data2 = np.array(data2)\n",
    "target = []\n",
    "for i in range(360):\n",
    "    target.append(int(i/10))\n",
    "target = np.array(target)\n",
    "print('Shape of dataset1: {}\\nand shape of dataset2:{}\\n and target: {}'.format(data.shape, data2.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the data, which is just the images flattened into a 1-d array\n",
    "for i in range(0, 4):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.axis('off')\n",
    "    imside = int(np.sqrt(data[i,].shape[0]))\n",
    "    im1 = np.reshape(data[i,], (imside, imside))\n",
    "    plt.imshow(im1, cmap=plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.title('Training: {}'.format(target[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and target sizes: \n",
      "(270, 147456), (270,)\n",
      "Test data and target sizes: \n",
      "(90, 147456), (90,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,target,random_state=0)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=0.001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = SVC(gamma = 0.001)\n",
    "#fit to the training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to predict the value of the rotation on the test data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(gamma=0.001):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       0.33      1.00      0.50         1\n",
      "           2       1.00      0.50      0.67         4\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      0.80      0.89         5\n",
      "           7       0.75      1.00      0.86         3\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       0.50      1.00      0.67         2\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       0.67      1.00      0.80         2\n",
      "          12       1.00      0.75      0.86         4\n",
      "          13       0.75      1.00      0.86         3\n",
      "          14       1.00      0.75      0.86         4\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       0.50      1.00      0.67         1\n",
      "          17       1.00      0.50      0.67         2\n",
      "          18       0.50      1.00      0.67         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       0.67      1.00      0.80         2\n",
      "          25       1.00      0.40      0.57         5\n",
      "          26       0.50      1.00      0.67         2\n",
      "          27       0.50      1.00      0.67         1\n",
      "          28       1.00      0.50      0.67         4\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.87      0.89      0.84        90\n",
      "weighted avg       0.91      0.84      0.84        90\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 2 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "(35, 35)\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n%s\" % conf_mat)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(conf_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
